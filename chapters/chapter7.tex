\chapter{Conclusions}\label{conclusions}
The success of Mu2e depends on many factors and one of them is the 
performance of the tracker. 
The tracker must provide excellent momentum resolution, approximately 1 MeV/c, 
to distinguish the monochromatic CE signal from the background. 
A straw tube tracker will be used, so the 
technology used is the drift tubes. This distinctive geometry 
is highly effective in reducing background, as it allows 
the passage of particles produced during muon capture, 
residual beam elements, and electrons from the initial proton collision, 
particles that would otherwise cause excessive instantaneous detector 
occupancy and accumulated radiation damage. The Mu2e straw tracker is placed inside the DS downstream from 
the ST in a 1 T uniform magnetic field. To minimise the probability of scattering and the energy loss of the CE, 
the volume inside the DS is evacuated to $10^{-4}$ Torr. The detector has a modular design, consisting 
of basic elements referred to as $Panel$s, $Face$s, $Plane$s, and $Station$s. The 
tracker comprises panels containing arrays of straw tubes, which are the 
sensitive units, arranged like the harp chords.

This Thesis has provided an in-depth examination of the Mu2e 
tracker system, from its initial stages of commissioning to the 
optimization of data acquisition and preliminary calibration steps. 
My work at Fermilab has focused on the 
complete Data Acquisition (DAQ) testing from both hardware and software 
perspectives. I was involved in the commissioning of the Mu2e DAQ system and 
the Vertical Slice Test (VST) of the tracker. The VST encompasses the entire 
testing chain, from the straws to the readout, to processed data on disk.
Throughout the chapters, we explored critical aspects of the tracker 
system, focusing on the robustness and reliability of data acquisition 
processes and the crucial role of calibration in ensuring precise measurements. 

\section{Commissioning of the tracker DAQ and FEE}
The first phase, described in Chapter \ref{commissioning}, 
was integral to the early phases of the Mu2e experiment, particularly in the context of the 
tracker system's DAQ and FEE testing. 
The first test I performed has been to verify the correct performance of ROC 
buffering. During these test, a single ROC was connected to the DTC. Data were collected
with digi-FPGAs pulsed by their internal pulsers, with the ROC set in the external
mode. ROC's digital readout logic allows to be emulated with a bit-level C++ simulation,
which I contributed to develop. The Monte Carlo and the data have been compared in two different 
modes: $ROC$ $buffer$ $overflow$ and $underflow$ configuration, at a channel occupancy level, studying 
the timing distribution and delays between channels and digi-FPGAs.

\section{Pre-pattern recognition studies}
Given the high data volume expected during Mu2e operations, estimated 
at approximately 7 PBytes per year, optimizing memory usage and minimizing 
CPU consumption are critical. A significant challenge lies in effectively 
flagging $\delta$-electron hits, which are the primary source of hits in 
the tracker, without compromising the efficiency of conversion electron 
hit detection and track reconstruction. $\delta$-electrons originate from 
Compton scattered electrons, pair production electrons and positrons, and 
delta rays. Compton scattered electrons are produced when photons, from 
neutron capture, interact with the detector material. Typically, these 
photons have energies of a few MeV. Pair production electrons and positrons 
are generated during nuclear recoil processes. Delta rays 
are produced when high-energy charged particles collide 
with the detector material. A detailed study of pre-pattern recognition 
and a thorough comparison of two algorithms for $\delta$-electron flagging is 
provided in Chapter \ref{delta} to address this issue.
The simulation shows that the majority 
(approximately 75\%) 
of hits in the tracker are generated by 
$\delta$-electrons, i.e. electrons 
and positrons with momenta below 20 MeV/c. 
Two distinct algorithms 
have been developed in Mu2e Offline to 
identify these hits and exclude 
them from the reconstruction process: 
$FlagBkgHits$ and $DeltaFinder$. 
The $FlagBkgHits$ algorithm initially 
clusters the hits and then uses an ANN 
to classify them, while $DeltaFinder$ 
identifies clusters of hits that are 
consistent with those produced by 
low-momentum particles.

I performed a systematic two-level comparison of the performance of the two algorithms:

\begin{itemize}
    \item Hit-level comparison: the focus is on evaluating the 
    accuracy with which individual hits are flagged, providing a 
    direct method for comparing the algorithms' performance. In terms 
    of $\delta$-electron flagging, both algorithms perform similarly. 
    However, $DeltaFinder$ performs better in flagging positrons 
    due to the low statistics at energies below 2 MeV/c, 
    while this disadvantages $FlagBkgHits$ since the ANN is 
    statistics dependent, though it 
    performs worse with electrons as it struggles to reconstruct hits 
    that register only a single hit per station.  
    $FlagBkgHits$ flags approximately 70\% more CE hits than 
    $DeltaFinder$, as it performs analysis on the $x$-$y$ plane and does 
    not reconstruct hits in the $z$ coordinate. Furthermore, 
    $DeltaFinder$ can flag proton hits (approximately 84\%), 
    a task that $FlagBkgHits$ cannot perform. It is crucial that hits 
    corresponding to $p\bar{p}$ annihilation are not flagged. This necessitates 
    examining muon and pion hit flagging, but $FlagBkgHits$ has been trained 
    on datasets lacking muon and pion hits and so 
    flags these particles at rates roughly 4 and 3.3 times higher, 
    respectively, than $DeltaFinder$;
    
    \item High-level comparison: this is a study of the algorithms' 
    impact on subsequent stages of event reconstruction, particularly 
    how effectively each contributes to accurate track reconstruction. 
    The main observed difference between the two algorithms lies in the number 
    of reconstructed tracks using CE data samples, which is 16\% higher 
    for $FlagBkgHits$. This increase is due to $FlagBkgHits$ failing to 
    properly flag protons, allowing these particles to be sent to the 
    reconstruction stage. The difference in the reconstruction of 
    $p\bar{p}$ events, measured as the fraction of events with 
    at least two reconstructed tracks, is approximately 22\% higher with $DeltaFinder$.
\end{itemize}
An important factor of study was the timing performance of the 
two algorithms. For $FlagBkgHits$, it was necessary to account for the time 
spent creating the $StereoHit$s, while $DeltaFinder$ independently 
reconstructed the $seed$s. Processing $CE-1BB$ sample required about 
0.14 ms/event for $FlagBkgHits$ plus an additional 0.15 ms/event, 
compared to 0.42 ms/event for $DeltaFinder$. For $CE-2BB$ events, 
$FlagBkgHits$ took approximately 0.37 ms/event plus 0.34 ms/event, 
while $DeltaFinder$ required 1.1 ms/event. Processing $PBAR-0BB$ 
events took about 0.02 ms/event plus 0.02 ms/event for $FlagBkgHits$, 
and 0.09 ms/event for $DeltaFinder$. The difference in processing time 
is negligible considering that the entire reconstruction process 
takes only a few ms per event.

The primary drawback of $FlagBkgHits$ is its reliance 
on supervised training using CE and $\delta$-electron samples. 
This approach fails when other particles, such as cosmic muons 
and those from $p\bar{p}$ annihilation, are introduced into the algorithm. 
Additionally, the training was performed using Monte Carlo data 
rather than real data, posing a potential risk when transitioning 
to actual data-taking. Moreover, being ANN-based, $FlagBkgHits$ 
performs poorly when the statistics are very low and lacks 
a well-defined method for proton flagging.

\section{First steps towards the station calibration}
Chapter \ref{planning} discusses the initial steps towards the tracker 
calibration. Our ultimate goal is to perform a time calibration of 
the first assembled station of the tracker using cosmic muons, aiming for a longitudinal hit 
position resolution better than 4 cm. This involves determining the signal 
propagation times and channel-to-channel delays. Due to technical constraints, the 
first option is to perform the with a vertically oriented station. I performed a 
Monte Carlo study to determine the impact of this orientation on the quality of the calibration, 
in particular on the cosmic track reconstruction, focusing on the 
potential biases that could arise. Together, 
these studies provide essential insights into the operation, optimization, 
and calibration of the Mu2e tracker system, contributing to its 
overall performance and reliability.
The Mu2e collaboration considered 
that a vertical station calibration might be 
feasible for our goals.
This Chapter demonstrated that the vertical orientation for calibrating a station is not optimal. This is due to several reasons:
\begin{itemize}
    \item The selection criteria in Section \ref{eventselection} select cosmic muons with orientations that affect panel illumination. 
    The illumination is non-uniform, and moreover, there are almost no hits in the central region of the panel, which could result in waveform non-linearities;
    \item The rate of cosmic events is $R \sim 380$ Hz, and the expected duration of the calibration is about 6 days without interruptions, 
    which is excessive for the simple calibration we intend to perform;
    \item The bias range is approximately [-6, 6] cm. The 2D distribution of the longitudinal bias versus the true position shows 
    four distinct spots on the $x$ axis corresponding to the overlap regions. Each spot refers to different straws.
\end{itemize}
Therefore, an alternative orientation or method should be considered to optimize the calibration process and achieve more accurate results.
For this reason, a new mechanical approach 
to address the problems outlined in Section \ref{gassystem}  
is currently under development.